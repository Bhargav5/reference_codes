{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D, Activation\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 256, 256\n",
    "train_data_dir = r\"C:\\\\Users\\\\Asus\\\\Untitled Folder\\\\train\\\\\"\n",
    "validation_data_dir = r\"C:\\\\Users\\\\Asus\\\\Untitled Folder\\\\validate\\\\\"\n",
    "nb_train_samples = 3312\n",
    "nb_validation_samples = 65\n",
    "batch_size = 64\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x000000E669F6D278>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000000E669F6D668>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000000E669F6D470>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000000E669F6DC50>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000000E669F98CC0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000000E66B175358>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000000E66B188EF0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000000E66B1AF7F0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000000E66B1C6CF8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000000E66B1DC668>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000000E66B1F2E48>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000000E66B217828>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000000E66B243278>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000000E66B243550>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000000E66B270B70>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000000E66B2808D0>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000000E66B2ACF60>\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers[:17]:\n",
    "    #layer.trainable = False\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding custom Layers \n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1)(x)\n",
    "predictions = Activation(\"sigmoid\")(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ac...)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# creating the final model \n",
    "model_final = Model(input = model.input, output = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3312 images belonging to 2 classes.\n",
      "Found 65 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_data_dir,target_size = (img_height, img_width),batch_size = batch_size, class_mode = \"binary\")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_data_dir,target_size = (img_height, img_width),class_mode = \"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model according to the conditions  \n",
    "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-db01f085f03e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msamples_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnb_train_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnb_val_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnb_validation_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model_final' is not defined"
     ]
    }
   ],
   "source": [
    "model_final.fit_generator(train_generator,samples_per_epoch = nb_train_samples,epochs = epochs,validation_data = validation_generator,nb_val_samples = nb_validation_samples,callbacks = [checkpoint, early])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.load_weights(\"first_try.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.evaluate_generator(validation_generator,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
